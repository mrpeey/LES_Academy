{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3a2a7f",
   "metadata": {},
   "source": [
    "# Task 3: Predictive Analytics for Resource Allocation\n",
    "\n",
    "# Predictive Analytics for Resource Allocation\n",
    "\n",
    "This notebook demonstrates predictive analytics using the Kaggle Breast Cancer Dataset. The goal is to preprocess the data, train a Random Forest model to predict issue priority (high/medium/low), and evaluate the model using accuracy and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401eea8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import pandas, numpy, scikit-learn, and matplotlib/seaborn for data handling, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91774cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a73b1",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Kaggle Breast Cancer Dataset\n",
    "Load the dataset into a pandas DataFrame, display the first few rows, and summarize key statistics and class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Kaggle Breast Cancer Dataset\n",
    "# Please ensure the dataset CSV is in the same directory or provide the correct path\n",
    "# Example filename: 'breast_cancer_data.csv'\n",
    "df = pd.read_csv('breast_cancer_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics and class distribution\n",
    "print('Dataset shape:', df.shape)\n",
    "df.describe()\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3e6a7",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing (Cleaning, Label Encoding, Splitting)\n",
    "Handle missing values, encode categorical variables (including mapping issue priority to high/medium/low), and split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning: Handle missing values\n",
    "print('Missing values per column:')\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Label Encoding: Map diagnosis to priority (example mapping)\n",
    "# You may need to adjust this mapping based on your use case\n",
    "def map_priority(diagnosis):\n",
    "    if diagnosis == 'M':\n",
    "        return 'high'\n",
    "    elif diagnosis == 'B':\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'medium'\n",
    "\n",
    "df['priority'] = df['diagnosis'].apply(map_priority)\n",
    "\n",
    "# Encode priority as numbers for classification\n",
    "priority_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df['priority_label'] = df['priority'].map(priority_mapping)\n",
    "\n",
    "# Feature selection (drop non-feature columns)\n",
    "X = df.drop(['diagnosis', 'priority', 'priority_label'], axis=1)\n",
    "y = df['priority_label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed917021",
   "metadata": {},
   "source": [
    "## 4. Train Random Forest Classifier to Predict Issue Priority\n",
    "Initialize and train a Random Forest classifier on the training data to predict the issue priority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d288c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5859d59",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance (Accuracy and F1-score)\n",
    "Use the trained model to predict on the test set and calculate accuracy and F1-score using scikit-learn metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1aa13",
   "metadata": {},
   "source": [
    "## 6. Display and Interpret Performance Metrics\n",
    "Display the calculated metrics and provide code to visualize the confusion matrix and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and classification report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=priority_mapping.keys(), yticklabels=priority_mapping.keys())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=priority_mapping.keys()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
